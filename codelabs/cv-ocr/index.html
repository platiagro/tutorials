
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Reconhecimento Ótico de Caracteres</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="cv-ocr"
                  title="Reconhecimento Ótico de Caracteres"
                  environment="web"
                  feedback-link="https://github.com/platiagro/tutorials">
    
      <google-codelab-step label="Função do componente" duration="0">
        <p>Utilização das bibliotecas <a href="https://opencv.org/" target="_blank">opencv</a> e  <a href="https://tesseract-ocr.github.io/" target="_blank">Tesseract OCR</a> para o reconhecimento de texto em imagens e da biblioteca <a href="https://github.com/jitsi/jiwer" target="_blank">JiWER</a> para cálculo de mérticas de perfomance.</p>
<ul>
<li>Mais detalhes sobre  o funcionamento dos algorítimos e das línguas nos quais o mesmo podem são utilizados são encontrados na <a href="https://tesseract-ocr.github.io/tessdoc/Data-Files" target="_blank">Tesseract documentation</a></li>
<li>Caso seja passado um arquivo .xlsx com as strings de target pode visualizar a perfonrmance do algorítimo</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Entrada esperada" duration="0">
        <p>Espera-se como entrada para o componente um arquivo .zip contendo images e podendo conter uma tabela .xlsx com uma coluna contendo as respostas esperadas.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Parâmetros" duration="0">
        <p>A seguir são listados todos os parâmetros utilizados pelo componente:</p>
<ul>
<li><strong>Caminho das imagens</strong>: <code>string</code>(Obrigatório).<br><em>Coluna da tabela com o caminho para as imagens.</em></li>
<li><strong>Atributo alvo</strong>: <code>string</code>.<br><em>Seu modelo será treinado para prever os valores do alvo.</em></li>
<li><strong>Confiabilidade do bbox</strong>: <code>integer</code>, padrão: <code>60</code>. <br><em>O quanto de confiabilidade o algorítmo deve possuir sobre o bbox para que o mesmo apareça.</em></li>
<li><strong>Modo de segmentação do PyTesseract</strong>, <code>string</code>, padrão: <code>Considere um único bloco de texto uniforme</code>. <br><em>Modo de segmentação utilizado pelo PyTesseract.</em></li>
<li><strong>OCR engine do Pytesseract</strong>. <br><em>Para mais informações acesse a documentação linkada no inicio do notebook.</em></li>
<li><strong>Idioma pré teinado</strong>, <code>string</code>, {<code>"por"</code>,<code>"eng"</code>}, padrão: <code>por</code>. <br><em>Opções disponibilizadas na aplicação compreendem português (por) e inglês (eng).</em></li>
<li><strong>Forma de retorno dos bboxes</strong>, <code>string</code>, {<code>"np_array"</code>, <code>"image"</code>}, padrão: <code>"np_array"</code>. <br><em>Escolher se bboxes serão retornados na imagem ou como um numpy array.</em></li>
<li><strong>Formato de retorno da imagem</strong>, <code>string</code>, {<code>"N/A"</code>, <code>".jpg"</code>, <code>".png"</code>}, padrão: <code>"N/A"</code>. <br><em>Escolher formato de retorno da imagem, N/A se retornar numpy array. Apenas aplicável caso bbox_return = image.</em></li>
<li><strong>Remove quebras de linha</strong>, <code>boolean</code>, {<code>True</code>, <code>False</code>}, padrão: <code>True</code>. <br><em>Caso True remove \n e \t dos resultados.Vale ressaltar que o texto de referência na tabela .xlsx caso haja, deve considerar este fato para calcular as métricas corretamente</em></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Métricas de performance" duration="0">
        <p>As métricas de performance tem o propósito de ajudar o usuário a avaliar a performance do modelo. Essas métricas variam de acordo com o tipo de problema, tal como: classificação, regressão, agrupamento, entre outros.</p>
<ol type="1">
<li>Word Error Rate (WER): Proporção de palavras erradas entre as palavras processadas. WER = ((S+D+I)/(H+S+D))</li>
<li>Match Error Rate (MER): Proporção de palavras correspondidas que são erros. MER = ((S+D+I)/(H+S+D+I))</li>
<li>Word Information Lost (WIL): Proporção de informação perdida. WIL = 1- ((H^2)/((H+S+D)(H+S+I)))</li>
<li>Word Information Preserved (WIP): Proporção de informação preservada. WIP = 1- WIL</li>
</ol>
<p>Legenda:  I= Número de Inserções, D = Número de Deleções, S = Número de Substituições, H = Número de Acertos.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Retorno esperado na experimentação" duration="0">
        <p>O retorno durante a experimentação ajuda o usuário a analisar tanto métricas distintas de forma visual, como a distribuição dos dados e os dados brutos ao final da execução. Sendo assim, é possível visualizar diversos retornos para este componente como os listados a seguir:</p>
<ol type="1">
<li>Tabela dos dados<br> <em>Dataframe com o texto de fererência, o texto encontrado, as coordenadas dos bboxes nas regiões em que os textos foram identificados e também as métricas calculadas. Em caso de não haver o arquivo .xlsx de referência, retorna apenas o texto encontrado e as coordenadas dos bboxes nas regiões em que os textos foram identificados.</em><img style="width: 800.00px" src="img/13ed870aa5e3607e.png"></li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Retorno esperado na implantação" duration="0">
        <p>Saída dependende do argumento do tipo de retorno. Caso seja uma imagem retorna um arquivo bytes em que o texto está marcado. Caso seja um numpy array retorna as posições dos bboxes em numpy array.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>

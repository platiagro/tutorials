
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Detecção de Faces</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="cv-mtcnn-face-detection"
                  title="Detecção de Faces"
                  environment="web"
                  feedback-link="https://github.com/platiagro/tutorials">
    
      <google-codelab-step label="Função do componente" duration="0">
        <p>Este componente utiliza a biblioteca <a href="https://github.com/timesler/facenet-pytorch" target="_blank">facenet-pytorch</a>, a qual disponibiliza o modelo <a href="https://arxiv.org/abs/1604.02878" target="_blank">MTCNN</a> para detecção de faces. O MTCNN possui a performance estado da arte nos benchmarks <a href="http://vis-www.cs.umass.edu/fddb/" target="_blank">FDDB</a> e <a href="http://shuoyang1213.me/WIDERFACE/" target="_blank">WIDER FACE</a>. Melhores explicações são encontradas neste <a href="https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch" target="_blank">artigo do kaggle</a>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Entrada esperada" duration="0">
        <p>Espera-se como entrada para o componente um arquivo .zip com imagens.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Parâmetros" duration="0">
        <p>A seguir são listados todos os parâmetros utilizados pelo componente:</p>
<ul>
<li><strong>Tamanho da imagem</strong>: <code>integer</code>, padrão: <code>160</code>.<br><em>Tamanho da imagem de saída em pixels. Imagem será quadrada.</em></li>
<li><strong>Margem adicionada ao bbox</strong>: <code>integer</code>, padrão: <code>20</code>.<br><em>Margem adicionada em relação ao número de pixels da imagem final.</em></li>
<li><strong>Menor tamanho de rosto</strong>: <code>integer</code>, padrão: <code>20</code>.<br><em>Menor tamanho de rosto que o algorítimo irá procurar em pixels.</em></li>
<li><strong>Fator de escalabilidade</strong>: <code>integer</code>: padrão: <code>0.709</code>.<br><em>Fator de escalabilidade para pirâmide de tamanhos de rosto.</em></li>
<li><strong>Manter todas as faces</strong>: <code>boolean</code>, {<code>True</code>, <code>False</code>}, padrão: <code>True</code>.<br><em>Se True retorna todas as faces, se não retorna apenas a com maior probabilidade caso encontre.</em></li>
<li><strong>Ambiente</strong>: <code>string</code>, {<code>"cuda"</code>, <code>"cpu"</code>}, padrão: <code>"cuda"</code>.<br><em>Escolher entre CPU e GPU. Se escolher GPU e não houver irá substituir automaticamente por cpu.</em></li>
<li><strong>Semente Aleatória</strong>: <code>integer</code>, padrão: <code>7</code>.<br><em>Semente para replicabilidade dos resultados.</em></li>
<li><strong>Batch size para inferência</strong>: <code>integer</code>, padrão: <code>2</code>.<br><em>Inferência em batch para acelerar o processo.</em></li>
<li><strong>Dimensão para redimensionamento</strong>: <code>integer</code>, padrão: <code>512</code>.<br><em>Dimensão em que todas as imagens serão redimensionadas para poderem ser procesadas em batch. Ficarão todas quadradas.</em></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Retorno esperado na experimentação" duration="0">
        <p>O retorno durante a experimentação ajuda o usuário a analisar tanto métricas distintas de forma visual, como a distribuição dos dados e os dados brutos ao final da execução. Sendo assim, é possível visualizar diversos retornos para este componente como os listados a seguir:</p>
<ol type="1">
<li>Tabela dos dados<br> <em>Apresenta visualização dos dados após o treinamento do modelo com a variável resposta e dados sobre o modelo.</em><img style="width: 800.00px" src="img/13ed870aa5e3607e.png"></li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Retorno esperado na implantação" duration="0">
        <p>Lista com todas as face ou apenas a face com maior probabilidade.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>


<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Detecção de Objetos</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="default-yolo"
                  title="Detecção de Objetos"
                  environment="web"
                  feedback-link="https://github.com/platiagro/tutorials">
    
      <google-codelab-step label="Função do componente" duration="0">
        <p>Este componente utiliza o algoritmo Yolo para detecção e classificação de objetos em imagens implementado na biblioteca <a href="https://pypi.org/project/yolov4/" target="_blank">Yolov4</a>. Essa biblioteca utiliza uma versão do modelo treinado com a base de dados Coco, e portanto, reconhece os objetos descritos em coco.names.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Entrada esperada" duration="0">
        <p>Espera-se como entrada para o componente um arquivo .zip com imagens.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Parâmetros" duration="0">
        <p>A seguir são listados todos os parâmetros utilizados pelo componente:</p>
<ul>
<li><strong>Linguagem</strong>: <code>string</code>, {<code>"português"</code>, <code>"inglês"</code>}, padrão: <code>"português"</code>.<br><em>O objeto detectado pode estar em português ou inglês.</em></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Retorno esperado na experimentação" duration="0">
        <p>O retorno durante a experimentação ajuda o usuário a analisar tanto métricas distintas de forma visual, como a distribuição dos dados e os dados brutos ao final da execução. Sendo assim, é possível visualizar diversos retornos para este componente como os listados a seguir:</p>
<ol type="1">
<li>Objetos identificados na imagem, probabilidade de cada objeto, e coordenadas das boundary boxes. <img style="width: 400.00px" src="img/cfc2d77eb702d9ee.png"></li>
</ol>
<h2 is-upgraded>Retorno esperado na implantação</h2>
<p>Objetos identificados na imagem, probabilidade de cada objeto, e coordenadas das boundary boxes.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
